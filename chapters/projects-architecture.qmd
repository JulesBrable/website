---
title: "Améliorer l'architecture de ses projets"
draft: false
# layout options: single, single-sidebar
layout: single
---

La structuration d'un projet
permet d'immédiatement identifier les éléments de code et les éléments
annexes, par exemple les dépendances à gérer, la documentation, etc.

Un certain nombre d'assistants au développement de projets orientés données
ont 
émergé pour gagner en productivité et faciliter le
lancement d'un projet (voir
[ce post très complet sur les extensions `VisualStudio`](https://realpython.com/advanced-visual-studio-code-python/)). 

L'idée générale est de privilégier une structure de projet
bien plus fiable qu'une suite sans structure de scripts
ou un _Notebook Jupyter_
(voir [ce post de blog sur ce sujet](https://www.tidyverse.org/blog/2017/12/workflow-vs-script/)).
L'IDE `Jupyter` n'est pas le meilleur outil pour le 
développement de projets `Python` ; pour des projets
intensifs en code il vaut mieux se tourner vers
des IDE classiques comme `VSCode`.


# Structure des projets {#structure}


La structure du projet suivante rend compliquée 
la compréhension du projet:

- Quelles sont les données en entrée de chaine ?
- Dans quel ordre les données intermédiaires sont-elles crées ?
- Quel est l'objet des productions graphiques ?


```
├── report.qmd
├── correlation.png
├── data.csv
├── data2.csv
├── fig1.png
├── figure 2 (copy).png
├── report.pdf
├── partial data.csv
├── script.R
└── script_final.py
```

Source : [eliocamp.github.io](https://eliocamp.github.io/reproducibility-with-r/materials/day1/02-projects/)


Les principes généraux sont les suivants:

1. Organiser son projet en sous-dossiers
2. Donner des noms pertinents aux fichiers
3. Documenter son projet
4. (Faire de son projet un ensemble de modules voire un package)

## Adopter une structure de projet


Le principe général d'une structure de projet est le suivant :

- Tous les fichiers nécessaires au projet dans un même dossier ;
- Le dossier à la racine du projet sert de *working directory* ;
- Utilisation de chemins relatifs plutôt qu'absolus.

Le principe d'une structure de projet est
d'adopter une structure arbitraire, mais lisible et cohérente.

```
├── README.md
├── .gitignore
├── data
│   ├── raw
│   │   ├── data.csv
│   │   └── data2.csv
│   └── derived
│       └── partial data.csv
├── src
|   ├── script.py
│   ├── script_final.py
│   └── report.qmd
└── output
    ├── fig1.png
    ├── figure 2 (copy).png
    ├── figure10.png
    ├── correlation.png
    └── report.pdf
```

Les _output_ sont stockés dans un dossier séparé, de même que les _inputs_. 
Idéalement les _inputs_ ne sont même pas stockés avec le code, nous reviendrons
sur la distinction entre l'espace de stockage du code et des données plus tard. 




::: {.callout-note}

Comme `Git` est un pré-requis, tout projet présente un fichier `.gitignore`
(il est très important, surtout quand on manipule des données qui ne
devraient pas se retrouver sur `Github` ou `Gitlab`).

Un projet présente aussi un fichier `README.md` à la racine, nous 
reviendrons dessus. 

Un projet qui utilise l'intégration continue présentera également : 

- si vous utilisez `Gitlab`, les instructions sont stockées dans
le fichier `gitlab-ci.yml`
- si vous utilisez `Github`, cela se passe dans le dossier `.github/workflows`

:::


## Autodocumenter le projet avec des noms pertinents

Rien qu'en changeant le nom des fichiers, on rend
la structure du projet très lisible:

```
├── README.md
├── .gitignore
├── data
│   ├── raw
│   │   ├── dpe_logement_202103.csv
│   │   └── dpe_logement_202003.csv
│   └── derived
│       └── dpe_logement_merged_preprocessed.csv
├── src
|   ├── preprocessing.py
│   ├── generate_plots.py
│   └── report.qmd
└── output
    ├── histogram_energy_diagnostic.png
    ├── barplot_consumption_pcs.png
    ├── correlation_matrix.png
    └── report.pdf
```

Maintenant, le type de données en entrée de chaine
est clair, le lien entre
les scripts, les données intermédiaires et les _output_ est assez
transparent. 


## Documenter son projet

Le fichier `README.md`, situé à la racine du projet, est à la fois la carte d'identité et la vitrine du projet.
Sur `Github` et `Gitlab`, comme il s'agit de l'élément qui s'affiche en accueil, ce 
fichier fait office de première impression,
instant très court qui peut être déterminant sur la valeur évaluée d'un projet. 

Idéalement, le `README.md` contient :

- Une présentation du contexte et des objectifs du projet
- Une description de son fonctionnement
- Un guide de contribution si le projet accepte des retours dans le cadre d'une démarche *open-source*

::: {.callout-note}

Quelques modèles de `README.md` complets, en `R` :

- [utilitR](https://github.com/InseeFrLab/utilitR/blob/master/README.md)
- [DoReMIFaSol](https://github.com/InseeFrLab/DoReMIFaSol)

:::

# Modularité

-   fonctions
-   modules



# Séparation données/code/config/environnement d'exécution

### Modèles

-   input / traitement / output
-   domain-driven design (data, domain, application, presentation)

### Templates

-   Python : cookiescutter


## Packages

La meilleure façon d'assurer la reproductibilité d'un projet est
d'intégrer ses scripts dans une structure de _package_.
Un gros projet
de _data-science_ va ainsi dépendre d'un ou plusieurs _packages_, ce qui 

- assure une gestion cohérente des dépendances
- offre une certaine structure pour la documentation
- facilitera sa réutilisation (les utilisateurs peuvent n'être intéressés
que par une partie du projet)
- permettra des économies d'échelle (on peut réutiliser
l'un des packages pour un autre projet)
- facilite le debuggage (il est
plus facile d'identifier une erreur quand elle est dans un package)
- ...


### Gestion des dépendances

TO DO


### Documentation

### Logging

### Tests unitaires

TO DO 

### Publication

Quand on débute, on est souvent timide et on désire ne rendre public
son code que lorsque celui-ci est propre. C'est une erreur classique:

{{< tweet 589068687669243905 >}}

Comme pour nettoyer un appartement, les petits gestes en continu
sont beaucoup plus efficace qu'un grand ménage de printemps.
Prendre l'habitude de mettre son code immédiatement sur `Github`
vous amènera à adopter de bons gestes. 

### Maintenance


L'objectif des conseils de ce cours est
de réduire le coût de la
maintenance à long terme en adoptant les structures
les plus légères, automatisées et 
réutilisables. 

Les notebooks Jupyter sont très pratiques pour tâtonner
et expérimenter. Cependant, ils présentent un certain
nombre d'inconvénients à long terme qui peuvent 
rendre impossible à maintenir le code écrit
avec dans un notebook:

- tous les objets (fonctions, classes et données)
sont définis et disponibles dans le même fichier.
Le moindre changement à une fonction nécessite de retrouver
l'emplacement dans le code, écrire et faire tourner à nouveau
une ou plusieurs cellules. 
- quand on tâtonne, on écrit du code dans des cellules. 
Dans un cahier, on utiliserait la marge mais cela n'existe
pas avec un notebook. On créé donc de nouvelles cellules, 
pas nécessairement dans l'ordre. Quand il est
nécessaire de faire tourner à nouveau le notebook, cela
provoque des erreurs difficile à debugger (il est nécessaire
de retrouver l'ordre logique du code, ce qui n'est pas
évident). 
- les notebooks incitent à faire des copier-coller de cellules
et modifier marginalement le code plutôt qu'à utiliser
des fonctions. 
- il est quasi-impossible d'avoir un versioning avec Git des notebooks
qui fonctionne. Les notebooks étant, en arrière plan, de gros fichiers
JSON, ils ressemblent plus à des données que des codes sources. Git ne
parvient pas à identifier les blocs de code qui ont changé
- passage en production des notebooks coûteux alors qu'un script bien
fait est beaucoup plus facile à passer en prod (voir suite cours)
- Jupyter manque d'extensions pour mettre en oeuvre les bonnes pratiques
(linters, etc.). VSCode au contraire est très bien 
- Risques de révélation de données confidentielles puisque les outputs
des blocs de code, par exemple les `head`, sont écrits en dur dans
le code source. 

Globalement, les notebooks sont un bon outil pour tâtonner ou pour
faire communiquer. Mais pour maintenir un projet à long terme, 
il vaut mieux privilégier les scripts. Les
recommandations de ce cours visent à rendre le plus léger possible
la maintenance à long terme de projets _data-science_ en favorisant
la reprise par d'autres (ou par soi dans le futur).



# Références

- [The Hitchhiker’s Guide to Python](https://docs.python-guide.org/#writing-great-python-code)
- [_Tidyverse style guide_](https://style.tidyverse.org/googl)
- [_Google style guide_](https://google.github.io/styleguide/Rguide.html)
- [Cours de Pierre-Antoine Champin](https://perso.liris.cnrs.fr/pierre-antoine.champin/enseignement/algo/cours/algo/bonnes_pratiques.html)
- [_R Packages_](https://r-pkgs.org/index.html) par Hadley Wickham and Jenny Bryan
- [La documentation collaborative `utilitR`](https://www.book.utilitr.org)
- [_Project Oriented Workflow_](https://www.tidyverse.org/blog/2017/12/workflow-vs-script/)
- [Un post très complet sur les extensions VisualStudio](https://realpython.com/advanced-visual-studio-code-python/)
- ["Coding style, coding etiquette"](https://blog.r-hub.io/2022/03/21/code-style/)

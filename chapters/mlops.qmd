---
title: "Vers le MLOps"
author: "Romain Avouac et Lino Galiana"
description: |
  <br>
  Présentation de l'approche MLOps.
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/mise-en-prod/army.png
order: 6
href: chapters/mlops.html
---


Grâce aux chapitres précédents on sait comment structurer et rendre son projet de de data science reproductible et portable grâce à l'approche DevOps. Pour de nombreux projets de data science cela peut s'avérer suffisant. Cependant, dès lors que l'on intègre un modèle de machine learning à notre projet l'approche DevOps devient alors une condition nécessaire mais plus suffisante pour réussir à mettre en production notre modèle. Aujourd'hui, une très grande majorité des modèles de machine learning ne dépassent pas le stade de l'expérimentation et très peu parviennent à atteindre le stade de la production. Pour simplifier ce passage vers la production une nouvelle approche a émergé en intégrant les spécificités des modèles de machine learning : le MLOps. On peut voir le MLOps comme la somme de 3 buzzwords à savoir :

MLOps = DataOps + DevOps + ModelOps

Ce chapitre définie cette approche et propose présente plusieurs outils pour l'adopter à ces projets de data science.



# Du DevOps vers le MLOps

## L'approche DevOps


L'approche DevOps, contraction des termes "Development" et "Operations", est une méthodologie de développement logiciel qui vise à améliorer la collaboration et la communication entre les équipes de développement (Dev) et l'administration système (Ops). Son objectif principal est d'accélérer et optimiser le cycle de vie du développement logiciel, de la conception à la production, en favorisant l'automatisation, l'intégration continue et le déploiement continu (cf. chapitre sur la mise en production).

Cette approche, datant de 2007, vise à éliminer les barrières traditionnelles entre le développement et l'informatique, favorisant ainsi une culture de responsabilité partagée. Les principes fondamentaux de DevOps incluent l'**automatisation** des processus, la **surveillance** continue des performances, la **gestion agile** des changements, et la création d'une **boucle de rétroaction** rapide pour améliorer en permanence les processus de développement et d'exploitation.

En résumé, DevOps vise à créer un écosystème de développement collaboratif, automatisé et axé sur l'amélioration continue. Le cycle de vie DevOps est souvent résumé par ces 8 phases inter-connectées : 

![](/devops.png){fig-align="center"}

## L'approche MLOps 

L'approche MLOps s'est construite sur les bases de l'approche DevOps. En cela on peut considérer qu'il s'agit simplement d'une extension à l'approche DevOps qui s'est développée pour répondre aux défis spécifiques liés à la gestion du cycle de vie des modèles de machine learning. Le MLOps intègre les principes de collaboration et d'automatisation propre au DevOps mais prend également en compte tous les aspects liés aux données et aux modèles de machine learning. 

Le MLOps implique l'**automatisation des tâches** telles que la gestion des données, le suivi des **versions des modèles**, leurs **déploiements**, ainsi que l'**évaluation continue** de la performance des modèles en production. De la même manière que le DevOps, le MLOps met l'accent sur la collaboration étroite entre les équipes de développement et de l'administration système d'une part ainsi que les équipes de data science d'autre pas. Cette collaboration est clé pour garantir une communication efficace tout au long du cycle de vie du modèle de machine learning.

Ainsi on définit généralement les 5 piliers du MLOps comme étant :

  - **la reproductibilité** : chaque expérimentation doit pouvoir être reproduite sans coût (gestion des packages, gestion des environnements, gestion des librairies système, gestion de version du code ...)
  - **la collaboration** : les différentes parties prenantes au projet doivent communiquer afin d'optimiser le cycle de vie du modèle en production
  - **l'automatisation** : le cycle de vie du modèle doit être automatisé au maximum avec des *pipeline* de CI/CD
  - **le contrôle de version des modèles** : chaque modèle doit avoir une version spécifique permettant de connaître sa situation tout au long de son cycle de vie (expérimental, en production, archivé...). De plus, un modèle ne dépend pas seulement des scripts associés, mais également des données utilisées lors de l'entraînement ce qui rend d'autant plus nécessaire une bonne gestion des versions
  - **la surveillance** : une fois déployé, il est important de s'assurer que le modèle fonctionne bien comme attendu en évaluant ses performances en temps réel

![](/mlops.png){fig-align="center"}

# Implémentation de l'approche MLOps avec MLflow

## Pourquoi MLflow ?

Il existe aujourd'hui de nombreux outils pour orchestrer des tâches et des pipelines de données. Parmi les plus populaires (selon leur ⭐ Github) on peut citer [Airflow](https://github.com/apache/airflow), [Luigi](https://github.com/spotify/luigi), [MLFlow](https://github.com/mlflow/mlflow), [Argo Workflow](https://github.com/argoproj/argo-workflows), [Prefect](https://github.com/PrefectHQ/prefect) ou encore [Kubeflow](https://github.com/kubeflow/kubeflow). Il est difficile d'affirmer s'il y en a un meilleur qu'un autre, en réalité votre choix dépend surtout de votre infrastructure informatique et de votre projet. En l’occurrence ici, nous avons fait le choix d'utiliser MLflow pour la simplicité d'utilisation mais aussi car il nous semble être le plus spécialisé pour les projet de machine learning. De plus, il est présent dans le catalogue du SSP Cloud ce qui simplifie grandement son installation. Nous utiliserons également [Argo CD](https://github.com/argoproj/argo-cd) et [Argo Workflow](https://github.com/argoproj/argo-workflows) plutôt qu'[Airflow](https://github.com/apache/airflow) car ils sont optimisés pour les clusters kubernetes (comme le SSP Cloud !).

MLflow est une plateforme qui permet d'optimiser le développement du cycle de vie d'un modèle de machine learning. Il permet de suivre en détails les différentes expérimentations, de *packager* son code pour garantir la reproductibilité, et de servir un modèle à des utilisateurs. MLFlow possède aussi une API qui permet d'être compatible avec la majorité des librairies de machine learning (PyTorch, Scikit learn, XGBoost, etc) mais également différents languages (python, R et Java).

## Les projets MLflow

MLflow propose un format pour *packager* son projet de data science afin de favoriser la réutilisation et la reproductibilité du code. Ce format s'appelle tout simplement *[MLflow Project](https://mlflow.org/docs/latest/projects.html)*. Concrètement un *MLflow project* n'est rien d'autre qu'un répertoire contenant le code et les ressources nécessaires (données, fichiers de configuration...) nécessaire à l'exécution de votre projet. Il est résumé par un ficher `MLproject` qui résume les différentes commandes pour exécuter une pipeline ainsi que les dépendances nécessaires. De manière général un projet MLflow a la structure suivante : 

```
Projet_ML/
├── artifacts/
│   ├── model.bin
│   └── train_text.txt
├── code/
│   ├── main.py
│   └── preprocessing.py
├── MLmodel
├── conda.yaml
├── python_env.yaml
├── python_model.pkl
└── requirements.txt
```


## Les modèles MLflow

En plus de *packager* son projet, MLflow permet de également de *packager* son modèle **quelque que soit** la librairie de machine learning sous-jacente utilisée (parmi celles [compatibles avec MLflow](https://mlflow.org/docs/latest/models.html#built-in-model-flavors), aka toutes les librairies que vous utilisez !). Ainsi, deux modèles entraînés avec des librairies différentes, disons PyTorch et Keras, peuvent être ainsi déployé et requêté de la même manière grâce à cette surcouche rajoutée par MLflow.

![](/mlflow-models.png){fig-align="center"}

::: {.callout-tip}
## Tip

Il est également possible de *packager* son propre modèle personnalisé ! Pour cela vous pouvez suivre le tutoriel présent dans la [documentation](https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html?highlight=custom%20models).
:::

## Le serveur de suivi (*tracking server*)

MLflow fourni un serveur de suivi qui contient à la fois une interface graphique ergonomique ainsi qu'une API permettant de *logger* différents paramètres, métriques, fichiers, etc durant l’entraînement de votre modèle de machine learning.
Le *tracking server* est très utile pour comparer les différentes expérimentations que vous avez effectué, pour les stocker et également pour être capable de les reproduire. En effet, chaque *run* sauvegarde la source des données utilisées mais également le commit sur lequel le *run* est basé. 

![](/tracking-server.png){fig-align="center"}


## L'entrepôt de modèles (*model registry*)

Une fois que l'on a effectué différentes expérimentations et pu sélectionner les modèles qui nous satisfont il est temps de passer à l'étape suivante du cycle de vie d'un modèle. En effet, le modèle choisi doit pouvoir ensuite passer dans un environnement de production ou de pré-production. Or, connaître l'état d'un modèle dans son cycle de vie nécessite une très bonne organisation et n'est pas si aisé. MLflow a développé une fonctionnalité qui permet justement de simplifier cette gestion des versions des modèles grâce à son [Model Registry](https://mlflow.org/docs/latest/model-registry.html). Cet entrepôt permet d'ajouter des tags et des alias à nos modèles pour définir leur position dans leur cycle de vie et ainsi pouvoir les récupérer de manière efficace. 

De manière générale un modèle de machine learning passe par 4 stades qu'il est nécessaire de pouvoir connaître en tout temps :

1. **Expérimental**
2. **En évaluation**
3. **En production**
4. **Archivé**

![](/mlflow-model-registry.png){fig-align="center"}

## MLflow en résumé

MLflow est donc un projet open-source qui fournit une plateforme pour suivre le cycle de vie d'une modèle de machine learning de bout en bout. Ce n'est pas le seul outil disponible et il n'est peut être pas le plus adapté à certains de vos projets précis. En revanche, il présente selon nous plusieurs avantages en premier desquels sa très simple prise en main et sa faculté à répondre aux besoins de l'approche MLOps. Il faut garder en tête que cet environnement est encore très récent et de nouveaux projets open-source émergent chaque jour, il est nécessaire de faire une veille sur les dernières évolutions. 

Pour résumer, MLFlow permet : 
- de simplifier le suivi de l’entraînement des modèles de machine learning grâce à son API et son *tracking server*
- d'intégrer les principaux framework de machine learning de manière simple
- d'intégrer son propre framework si besoin
- de standardiser son script d'entraînement et donc pouvoir l'industrialiser, pour réaliser un *fine-tuning* des hyper-paramètres par exemple
- de *packager* ses modèles, de sorte à pouvoir les requêter de manière simple et harmonisée entre les différents frameworks
- stocker ses modèles de manières pertinentes en leur affectant des tags et favorisant le suivi de leur cycle de vie

# Spécificités liées à la mise en prod de modèles de ML


## 1. Entraînements des modèles 

par nature, tous les projets ML suivent un développement non linéaire : différents preprocessing, feature engineering et algorithmes sont testés, jusqu’à ce qu’une performance suffisante soit atteinte. Garder une trace de ce qui a été expérimenté et de ce qui a ou non fonctionné peut s’avérer complexe. C’est pourtant crucial pour réduire le temps de développement, notamment dans le cas de grosses équipes, afin d’éviter de tester à nouveau des approches qui auraient déjà été expérimentées sans succès par un autre data scientist.

- Entraînement : batch ou online
- Distribuer l'entraînement des modèles : Argo workflow

## 2. Servir un modèle ML à des utilisateur

Il faut savoir que MLflow permet également de déployer directement un modèle MLflow. Cependant, nous avons décider de ne pas passer cette étape sous le tapis et de la détailler

- API Rest / FastAPI

- Batch vs real-time prediction 


## 3. Observabilité en temps réel d'un modèle de ML

- Drifts
- Quelles métriques monitorer


## 4. Réentraînement d'un modèle ML

Amélioration continue Réentraînement : périodique vs continu
- Feedback loops expérimentation/déploiement/monitoring

## 5. Défis organisationnels du MLOps

Pas ouf : 

Dans la plupart des organisations, les équipes data transverses ou intégrées dans différents départements métier sont relativement jeunes et manquent de ressources qualifiées pour gérer le déploiement et le maintien en condition opérationnelle de systèmes ML complexes. En effet, ces équipes se composent généralement principalement de data scientists qui se concentrent sur le développement des modèles de machine learning, mais n’ont pas les compétences nécessaires pour gérer le déploiement et la maintenance d’applications complètes. De plus, les équipes data évoluent encore trop souvent en silo, sans communiquer avec les différentes équipes techniques avec lesquelles elles devraient interagir pour mettre en production leurs modèles.
---
title: "Vers le MLOps"
author: "Romain Avouac et Lino Galiana"
description: |
  <br>
  Présentation de l'approche MLOps.
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/mise-en-prod/army.png
order: 6
href: chapters/mlops.html
---


On a vu comment déployer un projet data science. On est déjà aller loin dans la production. Cependant pour les projets de machine learning il y a d'autres enjeux qui apparaissent et qui doivent être pris en compte.

- Ou nous en sommes ?

Grâce aux chapitres précédents on sait comment structurer et rendre son projet de de data science reproductible et portable grâce à l'approche DevOps. Pour de nombreux projets de data science cela peut s'avérer suffisant. Cependant, dès lors que l'on intègre un modèle de machine learning à notre projet l'approche DevOps devient alors une condition nécessaire mais plus suffisante pour réussir à mettre en production notre modèle. Aujourd'hui, une très grande majorité des modèles de machine learning ne dépassent pas le stade de l'expérimentation et très peu parviennent à atteindre le stade de la production. Pour simplifier ce passage vers la production une nouvelle approche a émergé en intégrant les spécificités des modèles de machine learning : le MLOps. Ce chapitre définie cette approche et propose présente plusieurs outils pour l'adopter à ces projets de data science.


# Du DevOps vers le MLOps

## L'approche DevOps


L'approche DevOps, contraction des termes "Development" et "Operations", est une méthodologie de développement logiciel qui vise à améliorer la collaboration et la communication entre les équipes de développement (Dev) et l'administration système (Ops). Son objectif principal est d'accélérer et optimiser le cycle de vie du développement logiciel, de la conception à la production, en favorisant l'automatisation, l'intégration continue et le déploiement continu (cf. chapitre sur la mise en production).

Cette approche, datant de 2007, vise à éliminer les barrières traditionnelles entre le développement et l'informatique, favorisant ainsi une culture de responsabilité partagée. Les principes fondamentaux de DevOps incluent l'**automatisation** des processus, la **surveillance** continue des performances, la **gestion agile** des changements, et la création d'une **boucle de rétroaction** rapide pour améliorer en permanence les processus de développement et d'exploitation.

En résumé, DevOps vise à créer un écosystème de développement collaboratif, automatisé et axé sur l'amélioration continue. Le cycle de vie DevOps est souvent résumé par ces 8 phases inter-connectées : 

![](/devops.png)

## L'approche MLOps 

L'approche MLOps s'est construite sur les bases de l'approche DevOps. En cela on peut considérer qu'il s'agit simplement d'une extension à l'approche DevOps qui s'est développée pour répondre aux défis spécifiques liés à la gestion du cycle de vie des modèles de machine learning. Le MLOps intègre les principes de collaboration et d'automatisation propre au DevOps mais prend également en compte tous les aspects liés aux données et aux modèles de machine learning. 

Le MLOps implique l'**automatisation des tâches** telles que la gestion des données, le suivi des **versions des modèles**, leurs **déploiements**, ainsi que l'**évaluation continue** de la performance des modèles en production. De la même manière que le DevOps, le MLOps met l'accent sur la collaboration étroite entre les équipes de développement et de l'administration système d'une part ainsi que les équipes de data science d'autre pas. Cette collaboration est clé pour garantir une communication efficace tout au long du cycle de vie du modèle de machine learning.

Ainsi on définit généralement les 5 piliers du MLOps comme étant :

  - **la reproductibilité** : chaque expérimentation doit pouvoir être reproduite sans coût (gestion des packages, gestion des environnements, gestion des librairies système, gestion de version du code ...)
  - **la collaboration** : les différentes parties prenantes au projet doivent communiquer afin d'optimiser le cycle de vie du modèle en production
  - **l'automatisation** : le cycle de vie du modèle doit être automatisé au maximum avec des *pipeline* de CI/CD
  - **le contrôle de version des modèles** : chaque modèle doit avoir une version spécifique permettant de connaître sa situation tout au long de son cycle de vie (expérimental, en production, archivé...). De plus, un modèle ne dépend pas seulement des scripts associés, mais également des données utilisées lors de l'entraînement ce qui rend d'autant plus nécessaire une bonne gestion des versions
  - **la surveillance** : une fois déployé, il est important de s'assurer que le modèle fonctionne bien comme attendu en évaluant ses performances en temps réel


# Implémentation de l'approche MLOps avec MLflow

## Pourquoi MLflow ?

Il existe aujourd'hui de nombreux outils pour orchestrer des tâches et des pipelines de données. Parmi les plus populaires (selon leur ⭐ Github) on peut citer [Airflow](https://github.com/apache/airflow), [Luigi](https://github.com/spotify/luigi), [MLFlow](https://github.com/mlflow/mlflow), [Argo Workflow](https://github.com/argoproj/argo-workflows), [Prefect](https://github.com/PrefectHQ/prefect) ou encore [Kubeflow](https://github.com/kubeflow/kubeflow). Il est difficile d'affirmer s'il y en a un meilleur qu'un autre, en réalité votre choix dépend surtout de votre infrastructure informatique et de votre projet. En l’occurrence ici, nous avons fait le choix d'utiliser MLflow pour la simplicité d'utilisation mais aussi car il nous semble être le plus spécialisé pour les projet de machine learning. De plus, il est présent dans le catalogue du SSP Cloud ce qui simplifie grandement son installation. Nous utiliserons également [Argo CD](https://github.com/argoproj/argo-cd) et [Argo Workflow](https://github.com/argoproj/argo-workflows) plutôt qu'[Airflow](https://github.com/apache/airflow) car ils sont optimisés pour les clusters kubernetes (comme le SSP Cloud !).

MLflow est une plateforme qui permet d'optimiser le développement du cycle de vie d'un modèle de machine learning. Il permet de suivre en détails les différentes expérimentations, de *packager* son code pour garantir la reproductibilité, et de servir un modèle à des utilisateurs. MLFlow possède aussi une API qui permet d'être compatible avec la majorité des librairies de machine learning (PyTorch, Scikit learn, XGBoost, etc) mais également différents languages (python, R et Java).

## Les projets MLflow

MLflow propose un format pour *packager* son projet de data science afin de favoriser la réutilisation et la reproductibilité du code. Ce format s'appelle tout simplement *[MLflow Project](https://mlflow.org/docs/latest/projects.html)*. Concrètement un *MLflow project* n'est rien d'autre qu'un répertoire contenant le code et les ressources nécessaires (données, fichiers de configuration...) nécessaire à l'exécution de votre projet. Il est résumé par un ficher `MLproject` qui résume les différentes commandes pour exécuter une pipeline ainsi que les dépendances nécessaires. De manière général un projet MLflow a la structure suivante : 

Projet_ML/
├── artifacts/
│   ├── model.bin
│   └── train_text.txt
├── code/
│   ├── main.py
│   └── preprocessing.py
├── MLmodel
├── conda.yaml
├── python_env.yaml
├── python_model.pkl
└── requirements.txt


## Les modèles MLflow

En plus de *packager* son projet, MLflow permet de également de *packager* son modèle **quelque que soit** la librairie de machine learning sous-jacente utilisée (parmi celles [compatibles avec MLflow](https://mlflow.org/docs/latest/models.html#built-in-model-flavors), aka toutes les librairies que vous utilisez !). Ainsi, deux modèles entraînés avec des librairies différentes, disons PyTorch et Keras, peuvent être ainsi déployé et requêté de la même manière grâce à cette surcouche rajoutée par MLflow.

::: {.callout-tip}
## Tip

Il est également possible de *packager* son propre modèle personnalisé ! Pour cela vous pouvez suivre le tutoriel présent dans la [documentation](https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html?highlight=custom%20models)
:::

## Le serveur de suivi (*tracking server*)

MLflow fourni un serveur de suivi qui contient à la fois une interface graphique ergonomique ainsi qu'une API permettant de *logger* différents paramètres, métriques, fichiers, etc durant l’entraînement de votre modèle de machine learning.

![](/tracking-metrics-ui.png)


## l'entrepôt de modèles (*model registry*)

## MLflow en résumé

PARLER DES LIMITES DES NOTEBOOKS

# Spécificités liées à la mise en prod de modèles de ML

- Entraînement : batch ou online
- Batch vs real-time prediction 
- Feedback loops expérimentation/déploiement/monitoring
- Exposer le modèle via une API

# Servir un modèle ML à des utilisateur

- API Rest / FastAPI

## Notions d'observabilité

- Drifts
- Quelles métriques monitorer

## Distribuer l'entraînement des modèles

Argo workflow

## Amélioration continue

- Réentraînement : périodique vs continu
